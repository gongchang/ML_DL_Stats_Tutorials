{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05844e37-037d-412a-a383-1bff0bf1600a",
   "metadata": {},
   "source": [
    "# XAI: explainable AI, aka, interpretable machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ad05c-0920-4edb-90bf-bf9d0c127f21",
   "metadata": {},
   "source": [
    "There are several components of XAI:\n",
    "- explainable AI models: these models are self-explainable; for example, linear regression modesl where the weights are demonstrated by the coefficients of variable; another example is decision tree, where how classification is made is visually clear\n",
    "\n",
    "- explainable AI algorithms or techniques for otherwise black-box or hard-to-explain models; and this is the focus of this tutorial series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3cbf3-6e6e-48d5-a7d4-546ad8b819ec",
   "metadata": {},
   "source": [
    "We are going to cover a range of possible XAI techniques and the related python packages in the next tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca662335-f31b-4522-ae66-0d3891642a56",
   "metadata": {},
   "source": [
    "- Partial dependency plots (not covered with detailed tutorials; SHAP can achive similar purposes with better solution)\n",
    "- Permutation importance\n",
    "- LIME: it is a great tool for local interpretation of an instance, but doesn't come with the theoretical guaranttees that come with SHAP\n",
    "- SHAP: a great python package  with lots of useful plots and functions for usign the shapley values\n",
    "- Counterfactual: \n",
    "    - The current tutorial with alibi suggests it does not work well with sklearn models (also,it seems to only work with outdated tensorflow versions causing problem running it)\n",
    "    - A few more counterfactual explaination algorithms besides alibi that is worth trying the in future:\n",
    "        - DiCE: https://github.com/interpretml/DiCE\n",
    "        - CEML: https://github.com/andreArtelt/ceml\n",
    "_ Neural network interpretation\n",
    "    - There are a whole range of XAI algorithms for neural network interpreation, which will need a separate tutorials series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bccb9a0-72ef-4ffe-89ab-840d06dc2107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
