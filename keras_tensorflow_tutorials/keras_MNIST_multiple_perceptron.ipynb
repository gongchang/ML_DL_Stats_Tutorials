{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11476992/11490434 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "Y_Train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_Test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 625)               490625    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 625)               391250    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                6260      \n",
      "=================================================================\n",
      "Total params: 888,135\n",
      "Trainable params: 888,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"normal\", activation=\"sigmoid\", input_dim=784, units=625)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"normal\", activation=\"sigmoid\", input_dim=625, units=625)`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"normal\", activation=\"softmax\", input_dim=625, units=10)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Multilayer Perceptron model\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=625, input_dim=784, init='normal', activation='sigmoid'))\n",
    "model.add(Dense(output_dim=625, input_dim=625, init='normal', activation='sigmoid'))\n",
    "model.add(Dense(output_dim=10, input_dim=625, init='normal', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "#apparently these are old Keras API calls\n",
    "#the new Keras API calls would look like this:\n",
    "#Dense(kernel_initializer=\"normal\", activation=\"sigmoid\", input_dim=784, units=625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  128/60000 [..............................] - ETA: 32s - loss: 2.6901 - acc: 0.0859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s - loss: 1.9251 - acc: 0.4241     \n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.9224 - acc: 0.7837     \n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.5796 - acc: 0.8487     \n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.4688 - acc: 0.8720     \n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.4146 - acc: 0.8833     \n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.3840 - acc: 0.8907     \n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.3641 - acc: 0.8961     \n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.3488 - acc: 0.9000     \n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.3378 - acc: 0.9033     \n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.3289 - acc: 0.9048     \n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.3213 - acc: 0.9072     \n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.3146 - acc: 0.9090     \n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.3088 - acc: 0.9110     \n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.3040 - acc: 0.9117     \n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2995 - acc: 0.9133     \n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2954 - acc: 0.9145     \n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2915 - acc: 0.9155     \n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2883 - acc: 0.9169     \n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2851 - acc: 0.9179     \n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2817 - acc: 0.9184     \n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2793 - acc: 0.9189     \n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2762 - acc: 0.9196     \n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2728 - acc: 0.9216     \n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2699 - acc: 0.9216     \n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2673 - acc: 0.9228     \n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2646 - acc: 0.9234     \n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2619 - acc: 0.9249     \n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2594 - acc: 0.9250     \n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2565 - acc: 0.9257     \n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2539 - acc: 0.9266     \n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2510 - acc: 0.9277     \n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2488 - acc: 0.9281     \n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2458 - acc: 0.9296     \n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2426 - acc: 0.9299     \n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2402 - acc: 0.9308     \n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2375 - acc: 0.9317     \n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2349 - acc: 0.9325     \n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2315 - acc: 0.9337     \n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2288 - acc: 0.9345     \n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2267 - acc: 0.9349     \n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2231 - acc: 0.9361     \n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2205 - acc: 0.9371     \n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2176 - acc: 0.9378     \n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2152 - acc: 0.9383     \n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2123 - acc: 0.9395     \n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.2095 - acc: 0.9404     \n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2066 - acc: 0.9409     \n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2040 - acc: 0.9416     \n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.2013 - acc: 0.9425     \n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1988 - acc: 0.9430     \n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1958 - acc: 0.9441     \n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1937 - acc: 0.9445     \n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1910 - acc: 0.9453     \n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1884 - acc: 0.9462     \n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1858 - acc: 0.9470     \n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1834 - acc: 0.9476     \n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.1811 - acc: 0.9486     \n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.1789 - acc: 0.9493     \n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1767 - acc: 0.9496     \n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1741 - acc: 0.9498     \n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1722 - acc: 0.9512     \n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1698 - acc: 0.9512     \n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1679 - acc: 0.9521     \n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1655 - acc: 0.9529     \n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1637 - acc: 0.9535     \n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1619 - acc: 0.9536     \n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1594 - acc: 0.9543     \n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1578 - acc: 0.9549     \n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1561 - acc: 0.9548     \n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1539 - acc: 0.9556     \n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1519 - acc: 0.9565     \n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1499 - acc: 0.9567     \n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1485 - acc: 0.9569     \n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1466 - acc: 0.9578     \n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1450 - acc: 0.9581     \n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1433 - acc: 0.9587     \n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1417 - acc: 0.9592     \n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1400 - acc: 0.9593     \n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1382 - acc: 0.9602     \n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1368 - acc: 0.9612     \n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1352 - acc: 0.9610     \n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1337 - acc: 0.9616     \n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1318 - acc: 0.9620     \n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1306 - acc: 0.9624     \n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1291 - acc: 0.9630     \n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1277 - acc: 0.9632     \n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1261 - acc: 0.9636     \n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1249 - acc: 0.9643     \n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1235 - acc: 0.9644     \n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1217 - acc: 0.9646     \n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1207 - acc: 0.9652     \n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1194 - acc: 0.9658     \n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1179 - acc: 0.9660     \n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1167 - acc: 0.9663     \n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1153 - acc: 0.9666     \n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1143 - acc: 0.9671     \n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1128 - acc: 0.9674     \n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1119 - acc: 0.9676     \n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1104 - acc: 0.9680     \n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 5s - loss: 0.1096 - acc: 0.9681     \n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model.fit(X_train, Y_Train, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9184/10000 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, Y_Test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12412640523612499, 0.9623]\n"
     ]
    }
   ],
   "source": [
    "print evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
