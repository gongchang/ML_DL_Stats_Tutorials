{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The formula for calculating the output size for any given conv layer is\n",
    "\n",
    "O=(W-K+2P)/S + 1\n",
    "\n",
    "where O is the output height/length, W is the input height/length, K is the filter size, P is the padding, and S is the stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import initializations\n",
    "#In Keras 2.0,  initializations was renamed (mirror) as initializers\n",
    "from keras import initializers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 100\n",
    "\n",
    "img_rows, img_cols = 28, 28         # input image dimensions\n",
    "pool_size = (2, 2)                  # size of pooling area for max pooling\n",
    "prob_drop_conv = 0.2                # drop probability for dropout @ conv layer\n",
    "prob_drop_hidden = 0.5              # drop probability for dropout @ fc layer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The input shape that a CNN accepts should be in a specific format. If you are using Tensorflow, the format should be (batch, height, width, channels). \n",
    "If you are using Theano, the format should be (batch, channels, height, width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train original shape:', (60000, 28, 28))\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print('X_train original shape:', X_train.shape)\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    # For Theano backend\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    # For TensorFlow backend\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now the shape of X_train is (60000, 28, 28, 1). As all the images are in grayscale, the number of channels is 1. If it was a color image, then the number of channels would be 3 (R, G, B).\n",
    "\n",
    "Here we’ve rescaled the image data so that each pixel lies in the interval [0, 1] instead of [0, 255]. It is always a good idea to normalize the input so that each dimension has approximately the same scale.\n",
    "\n",
    "Now, we need to one-hot encode the labels i.e. Y_train and Y_test. In one-hot encoding an integer is converted to an array which contains only one ‘1’ and the rest elements are ‘0’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (60000, 28, 28, 1))\n",
      "(60000, 'train samples')\n",
      "(10000, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 625)               1280625   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                6260      \n",
      "=================================================================\n",
      "Total params: 1,379,557\n",
      "Trainable params: 1,379,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", kernel_initializer=<keras.ini..., input_shape=(28, 28, 1...)`\n",
      "  import sys\n",
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(padding=\"same\", strides=(2, 2), pool_size=(2, 2))`\n",
      "  \n",
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "  del sys.path[0]\n",
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(padding=\"same\", strides=(2, 2), pool_size=(2, 2))`\n",
      "  \n",
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(padding=\"same\", strides=(2, 2), pool_size=(2, 2))`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convolutional model\n",
    "model = Sequential()\n",
    "\n",
    "# conv1 layer\n",
    "#model.add(Convolution2D(32, 3, 3, border_mode='same', activation='relu', input_shape=input_shape, init=init_weights))\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', activation='relu', input_shape=input_shape, kernel_initializer=initializers.random_normal(stddev=0.01)))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2), border_mode='same'))\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# conv2 layer\n",
    "#model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', init=init_weights))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', kernel_initializer=initializers.random_normal(stddev=0.01)))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2), border_mode='same'))\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# conv3 layer\n",
    "#model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', init=init_weights))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', kernel_initializer=initializers.random_normal(stddev=0.01)))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2), border_mode='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# fc1 layer\n",
    "#model.add(Dense(625, activation='relu', init=init_weights))\n",
    "model.add(Dense(625, activation='relu', kernel_initializer=initializers.random_normal(stddev=0.01)))\n",
    "model.add(Dropout(prob_drop_hidden))\n",
    "\n",
    "# fc2 layer\n",
    "#model.add(Dense(10, activation='softmax', init=init_weights))\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer=initializers.random_normal(stddev=0.01)))\n",
    "\n",
    "opt = RMSprop(lr=0.001, rho=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hbi16859/anaconda/lib/python2.7/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 95s - loss: 0.4553 - acc: 0.8475    \n"
     ]
    }
   ],
   "source": [
    "# Train  set nb_epoch to be 1 just to try it\n",
    "#history = model.fit(X_train, Y_train, nb_epoch=nb_epoch, batch_size=batch_size, shuffle=True, verbose=1)\n",
    "history = model.fit(X_train, Y_train, nb_epoch=1, batch_size=batch_size, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0sSummary: Loss over the test dataset: 0.08, Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluation = model.evaluate(X_test, Y_test, batch_size=256, verbose=1)\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 100s - loss: 0.1130 - acc: 0.9650   \n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_train, Y_train, nb_epoch=1, batch_size=batch_size, shuffle=True, verbose=1,\n",
    "                    callbacks=[TensorBoard(log_dir='./logs/keras_convnet_one_pass_training', histogram_freq=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard 41 on port 6006\n",
      "(You can navigate to http://10.101.155.95:6006)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hbi16859/anaconda/bin/tensorboard\", line 6, in <module>\n",
      "    sys.exit(tensorflow.tensorboard.tensorboard.main())\n",
      "  File \"/Users/hbi16859/anaconda/lib/python2.7/site-packages/tensorflow/tensorboard/tensorboard.py\", line 151, in main\n",
      "    tb_server.serve_forever()\n",
      "  File \"/Users/hbi16859/anaconda/lib/python2.7/SocketServer.py\", line 231, in serve_forever\n",
      "    poll_interval)\n",
      "  File \"/Users/hbi16859/anaconda/lib/python2.7/SocketServer.py\", line 150, in _eintr_retry\n",
      "    return func(*args)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./logs/keras_convnet_one_pass_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 93s - loss: 0.0770 - acc: 0.9758    \n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 93s - loss: 0.0594 - acc: 0.9815    \n"
     ]
    }
   ],
   "source": [
    "history3 = model.fit(X_train, Y_train, nb_epoch=2, batch_size=batch_size, shuffle=True, verbose=1,\n",
    "                    callbacks=[TensorBoard(log_dir='./logs/keras_convnet_two_pass_training', histogram_freq=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard 41 on port 6006\n",
      "(You can navigate to http://10.101.155.95:6006)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hbi16859/anaconda/bin/tensorboard\", line 6, in <module>\n",
      "    sys.exit(tensorflow.tensorboard.tensorboard.main())\n",
      "  File \"/Users/hbi16859/anaconda/lib/python2.7/site-packages/tensorflow/tensorboard/tensorboard.py\", line 151, in main\n",
      "    tb_server.serve_forever()\n",
      "  File \"/Users/hbi16859/anaconda/lib/python2.7/SocketServer.py\", line 231, in serve_forever\n",
      "    poll_interval)\n",
      "  File \"/Users/hbi16859/anaconda/lib/python2.7/SocketServer.py\", line 150, in _eintr_retry\n",
      "    return func(*args)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./logs/keras_convnet_one_pass_training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Save and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, './logs/covnet_model_20180405')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('./logs/covnet_model_20180405')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59936/60000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02785647106292066, 0.9917]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
